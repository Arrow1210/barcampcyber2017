{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this demo, we're going to create 3 hidden layer Convolutional Neural Network model to classify 4 different kind of Malaysian Food. \n",
    "\n",
    "### Ais Kacang, Maggi Goreng, NasiLemak, Satay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'datasets/train'\n",
    "validation_data_dir = 'datasets/test'\n",
    "nb_train_samples = 100\n",
    "nb_validation_samples = 100\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first': #tensorflow\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else: # theano\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Conv Layer, 1 Fully Connected Layer + Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data generator  (Preprocess data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start feeding data and train the model ! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.8632 - acc: 0.2750Epoch 00000: val_acc improved from -inf to 0.23958, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 4s - loss: 1.7820 - acc: 0.2812 - val_loss: 1.3927 - val_acc: 0.2396\n",
      "Epoch 2/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3842 - acc: 0.2875Epoch 00001: val_acc improved from 0.23958 to 0.36458, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.3750 - acc: 0.3021 - val_loss: 1.3656 - val_acc: 0.3646\n",
      "Epoch 3/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3591 - acc: 0.3375Epoch 00002: val_acc improved from 0.36458 to 0.43750, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.4036 - acc: 0.2917 - val_loss: 1.3468 - val_acc: 0.4375\n",
      "Epoch 4/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3483 - acc: 0.4000Epoch 00003: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.3692 - acc: 0.3646 - val_loss: 1.3896 - val_acc: 0.3542\n",
      "Epoch 5/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3185 - acc: 0.3375Epoch 00004: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.3196 - acc: 0.3438 - val_loss: 1.2842 - val_acc: 0.3646\n",
      "Epoch 6/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3850 - acc: 0.3500Epoch 00005: val_acc improved from 0.43750 to 0.47917, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.3618 - acc: 0.3750 - val_loss: 1.2452 - val_acc: 0.4792\n",
      "Epoch 7/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1815 - acc: 0.4625Epoch 00006: val_acc improved from 0.47917 to 0.51042, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.2088 - acc: 0.4583 - val_loss: 1.1293 - val_acc: 0.5104\n",
      "Epoch 8/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1610 - acc: 0.5375Epoch 00007: val_acc improved from 0.51042 to 0.61458, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.1741 - acc: 0.5000 - val_loss: 1.0355 - val_acc: 0.6146\n",
      "Epoch 9/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9269 - acc: 0.5875Epoch 00008: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0025 - acc: 0.5521 - val_loss: 1.1857 - val_acc: 0.4583\n",
      "Epoch 10/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1667 - acc: 0.5000Epoch 00009: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.2322 - acc: 0.4479 - val_loss: 1.1653 - val_acc: 0.4688\n",
      "Epoch 11/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0314 - acc: 0.6000Epoch 00010: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0328 - acc: 0.5938 - val_loss: 1.0682 - val_acc: 0.5208\n",
      "Epoch 12/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0759 - acc: 0.5125Epoch 00011: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0637 - acc: 0.5208 - val_loss: 1.0176 - val_acc: 0.5104\n",
      "Epoch 13/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9147 - acc: 0.6750Epoch 00012: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.8906 - acc: 0.6875 - val_loss: 1.0712 - val_acc: 0.5417\n",
      "Epoch 14/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0901 - acc: 0.5500Epoch 00013: val_acc improved from 0.61458 to 0.65625, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.0428 - acc: 0.5729 - val_loss: 0.8906 - val_acc: 0.6562\n",
      "Epoch 15/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0441 - acc: 0.5375Epoch 00014: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9881 - acc: 0.5833 - val_loss: 0.8238 - val_acc: 0.6250\n",
      "Epoch 16/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9684 - acc: 0.6625Epoch 00015: val_acc improved from 0.65625 to 0.66667, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 0.9358 - acc: 0.6771 - val_loss: 0.9036 - val_acc: 0.6667\n",
      "Epoch 17/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9449 - acc: 0.5750Epoch 00016: val_acc improved from 0.66667 to 0.70833, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 0.9401 - acc: 0.5729 - val_loss: 0.8187 - val_acc: 0.7083\n",
      "Epoch 18/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8104 - acc: 0.6875Epoch 00017: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9085 - acc: 0.6562 - val_loss: 1.4447 - val_acc: 0.5833\n",
      "Epoch 19/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9411 - acc: 0.7125Epoch 00018: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9332 - acc: 0.6875 - val_loss: 1.0357 - val_acc: 0.5938\n",
      "Epoch 20/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8253 - acc: 0.6500Epoch 00019: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.7830 - acc: 0.6667 - val_loss: 1.2146 - val_acc: 0.5208\n",
      "Epoch 21/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9596 - acc: 0.6000Epoch 00020: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.8899 - acc: 0.6354 - val_loss: 0.7460 - val_acc: 0.6771\n",
      "Epoch 22/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6329 - acc: 0.8000Epoch 00021: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.6406 - acc: 0.7708 - val_loss: 1.2342 - val_acc: 0.5104\n",
      "Epoch 23/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6270 - acc: 0.7750Epoch 00022: val_acc improved from 0.70833 to 0.71875, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 0.6145 - acc: 0.7708 - val_loss: 0.7621 - val_acc: 0.7188\n",
      "Epoch 24/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0055 - acc: 0.5625Epoch 00023: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9614 - acc: 0.5938 - val_loss: 0.9290 - val_acc: 0.6250\n",
      "Epoch 25/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6264 - acc: 0.7750Epoch 00024: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.6896 - acc: 0.7292 - val_loss: 0.8272 - val_acc: 0.6771\n",
      "Epoch 26/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.6074 - acc: 0.8250Epoch 00025: val_acc improved from 0.71875 to 0.72917, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 0.6011 - acc: 0.8229 - val_loss: 0.6931 - val_acc: 0.7292\n",
      "Epoch 27/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5527 - acc: 0.7625Epoch 00026: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.7359 - acc: 0.7396 - val_loss: 1.0827 - val_acc: 0.5312\n",
      "Epoch 28/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7509 - acc: 0.6125Epoch 00027: val_acc improved from 0.72917 to 0.73958, saving model to weights.best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 0.7846 - acc: 0.6146 - val_loss: 0.6616 - val_acc: 0.7396\n",
      "Epoch 29/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5433 - acc: 0.8125Epoch 00028: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.5175 - acc: 0.8229 - val_loss: 0.6420 - val_acc: 0.7396\n",
      "Epoch 30/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.5728 - acc: 0.8000Epoch 00029: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.5613 - acc: 0.7812 - val_loss: 1.0865 - val_acc: 0.5729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d8ba3d128>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"weights-without-data-aug-best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n",
      "Found 400 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start the training !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 2.5927 - acc: 0.2500Epoch 00000: val_acc improved from -inf to 0.19792, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 4s - loss: 2.4006 - acc: 0.2708 - val_loss: 1.3837 - val_acc: 0.1979\n",
      "Epoch 2/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3936 - acc: 0.2625Epoch 00001: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.3824 - acc: 0.2917 - val_loss: 1.3930 - val_acc: 0.1771\n",
      "Epoch 3/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3694 - acc: 0.2500Epoch 00002: val_acc improved from 0.19792 to 0.41667, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.3632 - acc: 0.2708 - val_loss: 1.3209 - val_acc: 0.4167\n",
      "Epoch 4/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3681 - acc: 0.2750Epoch 00003: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.3627 - acc: 0.2917 - val_loss: 1.5736 - val_acc: 0.1771\n",
      "Epoch 5/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.4223 - acc: 0.2625Epoch 00004: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.4055 - acc: 0.3021 - val_loss: 1.2469 - val_acc: 0.2604\n",
      "Epoch 6/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3236 - acc: 0.3625Epoch 00005: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.3331 - acc: 0.3750 - val_loss: 1.3261 - val_acc: 0.2500\n",
      "Epoch 7/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2780 - acc: 0.3500Epoch 00006: val_acc improved from 0.41667 to 0.46875, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.2641 - acc: 0.3438 - val_loss: 1.1749 - val_acc: 0.4688\n",
      "Epoch 8/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.2203 - acc: 0.4875Epoch 00007: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.2283 - acc: 0.4688 - val_loss: 1.3642 - val_acc: 0.3438\n",
      "Epoch 9/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1922 - acc: 0.4625Epoch 00008: val_acc improved from 0.46875 to 0.53125, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.1733 - acc: 0.4792 - val_loss: 1.1375 - val_acc: 0.5312\n",
      "Epoch 10/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.3557 - acc: 0.3000Epoch 00009: val_acc improved from 0.53125 to 0.56250, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.3257 - acc: 0.3229 - val_loss: 1.0592 - val_acc: 0.5625\n",
      "Epoch 11/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1321 - acc: 0.3875Epoch 00010: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.1169 - acc: 0.3958 - val_loss: 1.0479 - val_acc: 0.5104\n",
      "Epoch 12/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1571 - acc: 0.4875Epoch 00011: val_acc improved from 0.56250 to 0.64583, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.1062 - acc: 0.5208 - val_loss: 0.9429 - val_acc: 0.6458\n",
      "Epoch 13/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1353 - acc: 0.5000Epoch 00012: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.1029 - acc: 0.5312 - val_loss: 1.2562 - val_acc: 0.4167\n",
      "Epoch 14/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0916 - acc: 0.5250Epoch 00013: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.1494 - acc: 0.5000 - val_loss: 0.9898 - val_acc: 0.5938\n",
      "Epoch 15/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0492 - acc: 0.5250Epoch 00014: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0345 - acc: 0.5312 - val_loss: 0.9185 - val_acc: 0.5729\n",
      "Epoch 16/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9404 - acc: 0.5875Epoch 00015: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9204 - acc: 0.6146 - val_loss: 1.3134 - val_acc: 0.4375\n",
      "Epoch 17/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1649 - acc: 0.4750Epoch 00016: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.1514 - acc: 0.4479 - val_loss: 1.2609 - val_acc: 0.4375\n",
      "Epoch 18/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0172 - acc: 0.5375Epoch 00017: val_acc improved from 0.64583 to 0.66667, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 1.0248 - acc: 0.5208 - val_loss: 0.8560 - val_acc: 0.6667\n",
      "Epoch 19/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9175 - acc: 0.6125Epoch 00018: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9279 - acc: 0.5833 - val_loss: 0.9256 - val_acc: 0.5417\n",
      "Epoch 20/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1819 - acc: 0.5000Epoch 00019: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.1285 - acc: 0.5312 - val_loss: 1.0078 - val_acc: 0.5312\n",
      "Epoch 21/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.1190 - acc: 0.5000Epoch 00020: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0827 - acc: 0.5208 - val_loss: 0.9442 - val_acc: 0.6146\n",
      "Epoch 22/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9377 - acc: 0.5625Epoch 00021: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9024 - acc: 0.5833 - val_loss: 1.0406 - val_acc: 0.5729\n",
      "Epoch 23/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9635 - acc: 0.5625Epoch 00022: val_acc improved from 0.66667 to 0.68750, saving model to weights-data-aug-best.hdf5\n",
      "6/6 [==============================] - 2s - loss: 0.9053 - acc: 0.5938 - val_loss: 0.7748 - val_acc: 0.6875\n",
      "Epoch 24/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9504 - acc: 0.6250Epoch 00023: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9686 - acc: 0.6042 - val_loss: 0.8521 - val_acc: 0.6458\n",
      "Epoch 25/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0588 - acc: 0.5750Epoch 00024: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0335 - acc: 0.5938 - val_loss: 1.0198 - val_acc: 0.5521\n",
      "Epoch 26/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9422 - acc: 0.5250Epoch 00025: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9054 - acc: 0.5729 - val_loss: 0.8450 - val_acc: 0.6458\n",
      "Epoch 27/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.8610 - acc: 0.6000Epoch 00026: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.8221 - acc: 0.6146 - val_loss: 0.9849 - val_acc: 0.6042\n",
      "Epoch 28/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.9050 - acc: 0.6375Epoch 00027: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.9128 - acc: 0.6458 - val_loss: 0.7907 - val_acc: 0.6771\n",
      "Epoch 29/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 1.0437 - acc: 0.5500Epoch 00028: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 1.0332 - acc: 0.5417 - val_loss: 0.9522 - val_acc: 0.6250\n",
      "Epoch 30/30\n",
      "5/6 [========================>.....] - ETA: 0s - loss: 0.7751 - acc: 0.6625Epoch 00029: val_acc did not improve\n",
      "6/6 [==============================] - 2s - loss: 0.7863 - acc: 0.6458 - val_loss: 0.8803 - val_acc: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1def25a30f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"weights-data-aug-best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets make some prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Satay': 3, 'Nasilemak': 2, 'MaggiGoreng': 1, 'AisKacang': 0}\n",
      "46.5029776096\n",
      "38.3441746235\n",
      "13.8513758779\n",
      "1.30147226155\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from scipy.misc import imread, imresize\n",
    "import numpy as np\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "#filename = 'datasets/test/Nasilemak/Nasilemak (179).jpg'\n",
    "#filename = 'datasets/test/Satay/Satay (261).jpg'\n",
    "#filename = 'datasets/test/Nasilemak/Nasilemak (179).jpg'\n",
    "filename = 'datasets/test/AisKacang/AisKacang (114).jpg'\n",
    "\n",
    "im = imresize(imread(filename),(150,150))\n",
    "im = im.transpose((1,0,2))\n",
    "im = np.expand_dims(im, axis=0)\n",
    "im = im.astype('float32')\n",
    "im /= 255\n",
    "\n",
    "out = model.predict(im)\n",
    "proba = np.argsort(out)[:,:-4-1:-1]\n",
    "\n",
    "print(out[0][proba][0][0]*100)\n",
    "print(out[0][proba][0][1]*100)\n",
    "print(out[0][proba][0][2]*100)\n",
    "print(out[0][proba][0][3]*100)\n",
    "\n",
    "print(np.argmax(out))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
